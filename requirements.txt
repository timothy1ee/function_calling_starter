#
# This file is autogenerated by pip-compile with Python 3.12
# by the following command:
#
#    pip-compile requirements.in
#
aiofiles==23.2.1
    # via chainlit
aiohappyeyeballs==2.4.4
    # via aiohttp
aiohttp==3.11.11
    # via litellm
aiosignal==1.3.2
    # via aiohttp
annotated-types==0.7.0
    # via pydantic
anyio==4.7.0
    # via
    #   asyncer
    #   httpx
    #   openai
    #   starlette
    #   watchfiles
asyncer==0.0.7
    # via chainlit
attrs==24.3.0
    # via
    #   aiohttp
    #   jsonschema
    #   referencing
bidict==0.23.1
    # via python-socketio
certifi==2024.12.14
    # via
    #   httpcore
    #   httpx
    #   requests
chainlit==1.3.2
    # via -r requirements.in
charset-normalizer==3.4.1
    # via requests
chevron==0.14.0
    # via literalai
click==8.1.8
    # via
    #   chainlit
    #   litellm
    #   uvicorn
dataclasses-json==0.6.7
    # via chainlit
deprecated==1.2.15
    # via
    #   opentelemetry-api
    #   opentelemetry-exporter-otlp-proto-grpc
    #   opentelemetry-exporter-otlp-proto-http
    #   opentelemetry-semantic-conventions
distro==1.9.0
    # via openai
fastapi==0.115.6
    # via chainlit
filelock==3.16.1
    # via huggingface-hub
filetype==1.2.0
    # via chainlit
frozenlist==1.5.0
    # via
    #   aiohttp
    #   aiosignal
fsspec==2024.12.0
    # via huggingface-hub
google-search-results==2.4.2
    # via -r requirements.in
googleapis-common-protos==1.66.0
    # via
    #   opentelemetry-exporter-otlp-proto-grpc
    #   opentelemetry-exporter-otlp-proto-http
grpcio==1.68.1
    # via opentelemetry-exporter-otlp-proto-grpc
h11==0.14.0
    # via
    #   httpcore
    #   uvicorn
    #   wsproto
httpcore==1.0.7
    # via httpx
httpx==0.27.2
    # via
    #   chainlit
    #   langsmith
    #   litellm
    #   literalai
    #   openai
huggingface-hub==0.27.0
    # via tokenizers
idna==3.10
    # via
    #   anyio
    #   httpx
    #   requests
    #   yarl
importlib-metadata==8.5.0
    # via
    #   litellm
    #   opentelemetry-api
jinja2==3.1.5
    # via litellm
jiter==0.8.2
    # via openai
jsonschema==4.23.0
    # via litellm
jsonschema-specifications==2024.10.1
    # via jsonschema
langsmith==0.2.7
    # via -r requirements.in
lazify==0.4.0
    # via chainlit
litellm==1.56.5
    # via -r requirements.in
literalai==0.0.623
    # via chainlit
markupsafe==3.0.2
    # via jinja2
marshmallow==3.23.2
    # via dataclasses-json
multidict==6.1.0
    # via
    #   aiohttp
    #   yarl
mypy-extensions==1.0.0
    # via typing-inspect
nest-asyncio==1.6.0
    # via chainlit
numpy==1.26.4
    # via chainlit
openai==1.58.1
    # via
    #   -r requirements.in
    #   litellm
opentelemetry-api==1.28.2
    # via
    #   opentelemetry-exporter-otlp-proto-grpc
    #   opentelemetry-exporter-otlp-proto-http
    #   opentelemetry-instrumentation
    #   opentelemetry-sdk
    #   opentelemetry-semantic-conventions
    #   uptrace
opentelemetry-exporter-otlp==1.28.2
    # via uptrace
opentelemetry-exporter-otlp-proto-common==1.28.2
    # via
    #   opentelemetry-exporter-otlp-proto-grpc
    #   opentelemetry-exporter-otlp-proto-http
opentelemetry-exporter-otlp-proto-grpc==1.28.2
    # via opentelemetry-exporter-otlp
opentelemetry-exporter-otlp-proto-http==1.28.2
    # via opentelemetry-exporter-otlp
opentelemetry-instrumentation==0.49b2
    # via uptrace
opentelemetry-proto==1.28.2
    # via
    #   opentelemetry-exporter-otlp-proto-common
    #   opentelemetry-exporter-otlp-proto-grpc
    #   opentelemetry-exporter-otlp-proto-http
opentelemetry-sdk==1.28.2
    # via
    #   opentelemetry-exporter-otlp-proto-grpc
    #   opentelemetry-exporter-otlp-proto-http
    #   uptrace
opentelemetry-semantic-conventions==0.49b2
    # via
    #   opentelemetry-instrumentation
    #   opentelemetry-sdk
orjson==3.10.13
    # via langsmith
packaging==23.2
    # via
    #   chainlit
    #   huggingface-hub
    #   literalai
    #   marshmallow
    #   opentelemetry-instrumentation
propcache==0.2.1
    # via
    #   aiohttp
    #   yarl
protobuf==5.29.2
    # via
    #   googleapis-common-protos
    #   opentelemetry-proto
pydantic==2.10.1
    # via
    #   -r requirements.in
    #   chainlit
    #   fastapi
    #   langsmith
    #   litellm
    #   literalai
    #   openai
pydantic-core==2.27.1
    # via pydantic
pyjwt==2.10.1
    # via chainlit
python-dotenv==1.0.1
    # via
    #   -r requirements.in
    #   chainlit
    #   litellm
python-engineio==4.11.2
    # via python-socketio
python-multipart==0.0.9
    # via chainlit
python-socketio==5.12.1
    # via chainlit
pyyaml==6.0.2
    # via huggingface-hub
referencing==0.35.1
    # via
    #   jsonschema
    #   jsonschema-specifications
regex==2024.11.6
    # via tiktoken
requests==2.32.3
    # via
    #   google-search-results
    #   huggingface-hub
    #   langsmith
    #   opentelemetry-exporter-otlp-proto-http
    #   requests-toolbelt
    #   serpapi
    #   tiktoken
requests-toolbelt==1.0.0
    # via langsmith
rpds-py==0.22.3
    # via
    #   jsonschema
    #   referencing
serpapi==0.1.5
    # via -r requirements.in
simple-websocket==1.1.0
    # via python-engineio
sniffio==1.3.1
    # via
    #   anyio
    #   httpx
    #   openai
starlette==0.41.3
    # via
    #   chainlit
    #   fastapi
syncer==2.0.3
    # via chainlit
tiktoken==0.8.0
    # via litellm
tokenizers==0.21.0
    # via litellm
tomli==2.2.1
    # via chainlit
tqdm==4.67.1
    # via
    #   huggingface-hub
    #   openai
typing-extensions==4.12.2
    # via
    #   anyio
    #   fastapi
    #   huggingface-hub
    #   openai
    #   opentelemetry-sdk
    #   pydantic
    #   pydantic-core
    #   typing-inspect
typing-inspect==0.9.0
    # via dataclasses-json
uptrace==1.28.2
    # via chainlit
urllib3==2.3.0
    # via requests
uvicorn==0.25.0
    # via chainlit
watchfiles==0.20.0
    # via chainlit
wrapt==1.17.0
    # via
    #   deprecated
    #   opentelemetry-instrumentation
wsproto==1.2.0
    # via simple-websocket
yarl==1.18.3
    # via aiohttp
zipp==3.21.0
    # via importlib-metadata
